{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22606,
     "status": "ok",
     "timestamp": 1562170993338,
     "user": {
      "displayName": "Cloud Machine",
      "photoUrl": "",
      "userId": "03543453517966682716"
     },
     "user_tz": 240
    },
    "id": "j1VJgbhjoy4a",
    "outputId": "fdc0045a-eb3f-4e07-a271-aa1ef2bc5642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/FirmAI/FinML/Data/Equity Factors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import packages\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Initialization Settings\n",
    "\n",
    "## Save future files to your drive\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)\n",
    "%cd \"/content/drive/My Drive/FirmAI/FinML/Data/Equity Factors\"\n",
    "\n",
    "\n",
    "DATE = '6/30/2017' # Analysis date\n",
    "PERIOD = 24 # No. of months to use in calculating factor betas\n",
    "DIR = 'input' # Input directory\n",
    "PORT_FILE = '{0}/portfolio.csv'.format(DIR) # Current portfolio\n",
    "BENCH_FILE = '{0}/benchmark.csv'.format(DIR) # Current benchmark\n",
    "UNV_FILE = '{0}/universe.csv'.format(DIR) # Current universe\n",
    "PRI_FILE = '{0}/price.csv'.format(DIR) # Price file\n",
    "SHR_FILE  = '{0}/shrsout.csv'.format(DIR) # Shares outstanding file\n",
    "EPS_FILE  = '{0}/eps.csv'.format(DIR) # Earnings per share (EPS) file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SwE_FuGpQep"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Portfolio, benchmark, and active risks\n",
    "\n",
    "\n",
    "# Class that performs all risk model calculations\n",
    "class RiskModel():\n",
    "    \n",
    "    def __init__(self, port):\n",
    "        self.port = port\n",
    "    \n",
    "    # Total risk (portfolio-level)\n",
    "    def factor_risk_total(self):\n",
    "        return float(np.sqrt(np.dot(np.dot(self.port.T, factor_risk), self.port)))\n",
    "    def specific_risk_total(self):\n",
    "        return float(np.sqrt(np.dot(np.dot(self.port.T, specific_risk), self.port)))\n",
    "    def total_risk_total(self):\n",
    "        return float(np.sqrt(np.dot(np.dot(self.port.T, total_risk), self.port)))\n",
    "\n",
    "    # Marginal risk (stock-level)\n",
    "    def factor_risk_marginal(self):\n",
    "        return np.concatenate(np.dot(factor_risk, self.port) / self.factor_risk_total() / 100, axis=0)\n",
    "    def specific_risk_marginal(self):\n",
    "        return np.concatenate(np.dot(specific_risk, self.port) / self.specific_risk_total() / 100, axis=0)\n",
    "    def total_risk_marginal(self):\n",
    "        return np.concatenate(np.dot(total_risk, self.port) / self.total_risk_total() / 100, axis=0)\n",
    "    \n",
    "    # Contribution to risk (stock-level)\n",
    "    def factor_risk_contrib(self):\n",
    "        return np.concatenate(np.array(self.port), axis=0) * self.factor_risk_marginal() * 100\n",
    "    def specific_risk_contrib(self):\n",
    "        return np.concatenate(np.array(self.port), axis=0) * self.specific_risk_marginal() * 100\n",
    "    def total_risk_contrib(self):\n",
    "        return np.concatenate(np.array(self.port), axis=0) * self.total_risk_marginal() * 100\n",
    "    \n",
    "    # Percent contribution to risk (stock-level)\n",
    "    def factor_risk_pct_contrib(self):\n",
    "        return ((self.factor_risk_total()**2 / self.total_risk_total()**2) * \n",
    "                self.factor_risk_contrib() / np.sum(self.factor_risk_contrib()))\n",
    "    def specific_risk_pct_contrib(self):\n",
    "        return ((self.specific_risk_total()**2 / self.total_risk_total()**2) * \n",
    "                self.specific_risk_contrib() / np.sum(self.specific_risk_contrib()))\n",
    "    def total_risk_pct_contrib(self):\n",
    "        return ((self.total_risk_total()**2 / self.total_risk_total()**2) * \n",
    "                self.total_risk_contrib() / np.sum(self.total_risk_contrib()))\n",
    "\n",
    "    # Portfolio factor risk decomposition\n",
    "    def factor_decomp_marginal(self):\n",
    "        return np.dot(factor_covar, np.dot(self.port.T, factor_exposure).T) / self.factor_risk_total() / 100\n",
    "    def factor_decomp_contrib(self):\n",
    "        return np.dot(self.port.T, factor_exposure).T * self.factor_decomp_marginal() * 100\n",
    "    def factor_decomp_pct_contrib(self):\n",
    "        return self.factor_decomp_contrib() / self.factor_risk_total()\n",
    "\n",
    "\n",
    "# Data import\n",
    "\n",
    "\n",
    "portfolio = pd.read_csv(PORT_FILE, index_col='TICKER', header=0) # Portfolio\n",
    "benchmark = pd.read_csv(BENCH_FILE, index_col='TICKER', header=0) # Benchmark\n",
    "active = portfolio - benchmark # Active portfolio\n",
    "\n",
    "wgt = pd.read_csv(UNV_FILE, header=0, index_col='DATE', parse_dates=['DATE'])\n",
    "pri = pd.read_csv(PRI_FILE, header=0, index_col='DATE', parse_dates=['DATE'])\n",
    "shr = pd.read_csv(SHR_FILE, header=0, index_col='DATE', parse_dates=['DATE'])\n",
    "eps = pd.read_csv(EPS_FILE, header=0, index_col='DATE', parse_dates=['DATE'])\n",
    "\n",
    "\n",
    "# Create factors\n",
    "\n",
    "\n",
    "# size: 1. Factor: Size\n",
    "# ====  2. Definition: Natural log of market cap\n",
    "#       3. Scaling: The values are normalized\n",
    "#\n",
    "# valu: 1. Factor: Value\n",
    "# ====  2. Definition: Earnings yield = EPS / price\n",
    "#       3. Scaling: The values are normalized\n",
    "#       4. Note: Earnings is lagged by two months to account for delay in earnings data\n",
    "#\n",
    "# mntm: 1. Factor: Momentum\n",
    "# ====  2. Definition: Price change from 12 months ago to 1 month ago \n",
    "#       3. Scaling: The values are normalized\n",
    "\n",
    "factor_size = np.log(pri*shr)\n",
    "factor_size_norm = factor_size.sub(factor_size.mean(axis=1), axis=0).div(factor_size.std(axis=1), axis=0)\n",
    "\n",
    "factor_valu  = eps.shift(2).rolling(window=12, min_periods=None).sum() / pri\n",
    "factor_valu_norm = factor_valu.sub(factor_valu.mean(axis=1), axis=0).div(factor_valu.std(axis=1), axis=0)\n",
    "\n",
    "factor_mntm = pri.shift(1).pct_change(periods=11)\n",
    "factor_mntm_norm = factor_mntm.sub(factor_mntm.mean(axis=1), axis=0).div(factor_mntm.std(axis=1), axis=0)\n",
    "\n",
    "# Stack factors to prepare for regression analysis\n",
    "# Note: factors are lagged by one month so that they are aligned with the\n",
    "# subsequent monthly price return\n",
    "stack_pret = pd.DataFrame(pri.pct_change(periods=1).subtract(np.sum(wgt * pri.pct_change(periods=1),axis=1),axis=0).stack())\n",
    "stack_factor_size_norm = pd.DataFrame(factor_size_norm.shift(1).stack())\n",
    "stack_factor_valu_norm = pd.DataFrame(factor_valu_norm.shift(1).stack())\n",
    "stack_factor_mntm_norm = pd.DataFrame(factor_mntm_norm.shift(1).stack())\n",
    "stack = pd.concat([stack_pret, stack_factor_size_norm, stack_factor_valu_norm, stack_factor_mntm_norm], axis=1)\n",
    "stack.columns = ['pret', 'size', 'valu', 'mntm']\n",
    "stack.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# Regression analysis\n",
    "\n",
    "\n",
    "betas = [] # Betas\n",
    "preds = [] # Predictions\n",
    "resid = [] # Residuals\n",
    "\n",
    "for i in stack.index.levels[0][-PERIOD:]:\n",
    "    y = stack.loc[(i)]['pret']\n",
    "    X = stack.loc[(i)][['size','valu','mntm']]\n",
    "    \n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X,y)\n",
    "\n",
    "    betas.append(model.coef_)\n",
    "    preds.append(model.predict(X))\n",
    "    resid.append(y - model.predict(X))\n",
    "\n",
    "betas = np.array(betas)\n",
    "preds = np.array(preds)\n",
    "resid = np.array(resid)\n",
    "\n",
    "# Factor covariance/correlation matrix\n",
    "factor_covar = np.cov(betas.T, ddof=1) * 12\n",
    "factor_corr = np.corrcoef(betas.T)\n",
    "\n",
    "# Factor exposures\n",
    "factor_exposure = np.array(pd.concat([factor_size_norm.loc[DATE], \n",
    "                                     factor_valu_norm.loc[DATE], \n",
    "                                     factor_mntm_norm.loc[DATE],\n",
    "                                     ],axis=1))\n",
    "\n",
    "# Risk matrices for factor, specific, and total risk (of size NxN)\n",
    "factor_risk = np.dot(np.dot(factor_exposure, factor_covar), factor_exposure.T)\n",
    "specific_risk = np.diag((np.std(resid, ddof=1, axis=0) * np.sqrt(12))**2)\n",
    "total_risk = factor_risk + specific_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1562171012424,
     "user": {
      "displayName": "Cloud Machine",
      "photoUrl": "",
      "userId": "03543453517966682716"
     },
     "user_tz": 240
    },
    "id": "IHUJ0XM1pbXw",
    "outputId": "23f3981b-49bb-47e4-bff8-b3252cd737cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.49922513e-02,  4.74780318e-03, -1.61388106e-03,\n",
       "        -5.14040407e-03,  6.63967657e-03, -1.74133169e-02,\n",
       "         1.05997095e-02, -1.53489987e-02, -8.04510231e-03,\n",
       "         6.32461073e-03],\n",
       "       [ 4.74780318e-03,  2.32414053e-02,  3.34823821e-03,\n",
       "        -3.07532274e-03,  1.97226377e-03, -6.67259153e-03,\n",
       "         1.82484665e-03, -5.08286719e-04, -5.12255252e-03,\n",
       "         1.39265350e-04],\n",
       "       [-1.61388106e-03,  3.34823821e-03,  3.10007390e-02,\n",
       "        -1.21521161e-03, -5.23923466e-03, -1.79954289e-03,\n",
       "        -5.96632752e-04,  5.72556101e-03, -3.57289120e-03,\n",
       "        -2.59272368e-03],\n",
       "       [-5.14040407e-03, -3.07532274e-03, -1.21521161e-03,\n",
       "         1.91005724e-02, -1.00082501e-02,  7.88977209e-03,\n",
       "         3.24525108e-04, -4.48476215e-04,  6.50704020e-03,\n",
       "         7.26858003e-05],\n",
       "       [ 6.63967657e-03,  1.97226377e-03, -5.23923466e-03,\n",
       "        -1.00082501e-02,  6.94239236e-02, -1.09047470e-02,\n",
       "        -5.42629699e-03,  1.75039172e-03, -9.53662830e-03,\n",
       "        -1.20972854e-04],\n",
       "       [-1.74133169e-02, -6.67259153e-03, -1.79954289e-03,\n",
       "         7.88977209e-03, -1.09047470e-02,  2.66868711e-02,\n",
       "        -7.30191230e-03,  9.26317570e-03,  1.17053811e-02,\n",
       "        -3.83729766e-03],\n",
       "       [ 1.05997095e-02,  1.82484665e-03, -5.96632752e-04,\n",
       "         3.24525108e-04, -5.42629699e-03, -7.30191230e-03,\n",
       "         3.95770579e-02, -1.16952455e-02, -1.31900612e-03,\n",
       "         4.65261952e-03],\n",
       "       [-1.53489987e-02, -5.08286719e-04,  5.72556101e-03,\n",
       "        -4.48476215e-04,  1.75039172e-03,  9.26317570e-03,\n",
       "        -1.16952455e-02,  4.16286841e-02,  2.47273491e-04,\n",
       "        -7.66100506e-03],\n",
       "       [-8.04510231e-03, -5.12255252e-03, -3.57289120e-03,\n",
       "         6.50704020e-03, -9.53662830e-03,  1.17053811e-02,\n",
       "        -1.31900612e-03,  2.47273491e-04,  2.30044352e-02,\n",
       "        -1.35125340e-04],\n",
       "       [ 6.32461073e-03,  1.39265350e-04, -2.59272368e-03,\n",
       "         7.26858003e-05, -1.20972854e-04, -3.83729766e-03,\n",
       "         4.65261952e-03, -7.66100506e-03, -1.35125340e-04,\n",
       "         2.99554844e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6LqvcnhpfP_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Equity Factors.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
